"""
Agentic File Workflow Tool — FastMCP 2.14.1+ Sampling Implementation

Uses ctx.sample() with tools (SEP-1577) so the client's LLM autonomously
orchestrates multi-step file management operations.  The server passes a
set of file-operation helper functions to ctx.sample(); the LLM decides
which ones to call, in what order, and synthesises the final answer.

No mock.  No pattern-matching.  The LLM does the work.
"""

import logging
import os
from typing import Optional

from fastmcp import Context
from pydantic import BaseModel

logger = logging.getLogger(__name__)

from .. import app  # noqa: E402
from .utils import _error_response  # noqa: E402


# ── Structured result type ────────────────────────────────────────────────────

class WorkflowResult(BaseModel):
    """Structured result returned by the sampling LLM."""
    summary: str
    steps_taken: list[str]
    findings: list[dict]
    success: bool
    notes: Optional[str] = None


# ── Sampling tool functions (passed to ctx.sample as tools) ──────────────────
# These are plain Python functions.  FastMCP turns them into tool schemas
# from their type hints and docstrings automatically.

def read_text_file(path: str) -> str:
    """Read the full text content of a file at the given absolute path."""
    try:
        with open(path, encoding="utf-8", errors="replace") as f:
            return f.read()
    except FileNotFoundError:
        return f"ERROR: File not found: {path}"
    except PermissionError:
        return f"ERROR: Permission denied: {path}"
    except Exception as e:
        return f"ERROR: {e}"


def read_file_lines(path: str, start: int = 1, end: int = 50) -> str:
    """
    Read specific lines from a file (1-indexed, inclusive).
    Useful for large files — read only the relevant section.
    """
    try:
        with open(path, encoding="utf-8", errors="replace") as f:
            lines = f.readlines()
        selected = lines[max(0, start - 1): end]
        return "".join(selected)
    except FileNotFoundError:
        return f"ERROR: File not found: {path}"
    except Exception as e:
        return f"ERROR: {e}"


def list_directory(path: str) -> str:
    """
    List files and subdirectories in the given directory path.
    Returns one entry per line in the format: [FILE|DIR] name
    """
    try:
        entries = os.scandir(path)
        lines = []
        for e in sorted(entries, key=lambda x: (not x.is_dir(), x.name)):
            tag = "DIR" if e.is_dir() else "FILE"
            lines.append(f"[{tag}] {e.name}")
        return "\n".join(lines) if lines else "(empty directory)"
    except FileNotFoundError:
        return f"ERROR: Directory not found: {path}"
    except Exception as e:
        return f"ERROR: {e}"


def file_exists(path: str) -> str:
    """Check whether a file or directory exists at the given path."""
    if os.path.isfile(path):
        size = os.path.getsize(path)
        return f"EXISTS: file, {size} bytes"
    if os.path.isdir(path):
        return "EXISTS: directory"
    return "NOT_FOUND"


def find_files(directory: str, pattern: str) -> str:
    """
    Recursively find files under directory whose name contains pattern (case-insensitive).
    Returns up to 50 matches, one per line (absolute paths).
    """
    try:
        matches = []
        pat = pattern.lower()
        for root, _dirs, files in os.walk(directory):
            for fname in files:
                if pat in fname.lower():
                    matches.append(os.path.join(root, fname))
                    if len(matches) >= 50:
                        break
            if len(matches) >= 50:
                break
        if not matches:
            return f"No files matching '{pattern}' found under {directory}"
        return "\n".join(matches)
    except Exception as e:
        return f"ERROR: {e}"


def get_file_info(path: str) -> str:
    """
    Return metadata for a file: size, modification time, line count.
    """
    try:
        import datetime
        stat = os.stat(path)
        mtime = datetime.datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S")
        with open(path, encoding="utf-8", errors="replace") as f:
            lines = sum(1 for _ in f)
        return f"size={stat.st_size} bytes | modified={mtime} | lines={lines}"
    except FileNotFoundError:
        return f"ERROR: File not found: {path}"
    except Exception as e:
        return f"ERROR: {e}"


# ── Sampling tool registry ─────────────────────────────────────────────────────

_ALL_SAMPLING_TOOLS = {
    "file_ops":    [read_text_file, read_file_lines, get_file_info, file_exists],
    "dir_ops":     [list_directory, find_files, file_exists],
    "search_ops":  [find_files, list_directory],
    "read_ops":    [read_text_file, read_file_lines, get_file_info],
}

_FALLBACK_TOOLS = [read_text_file, list_directory, find_files, file_exists, get_file_info]


def _resolve_tools(available_tools: list[str]) -> list:
    """Map tool group names → actual Python functions (deduplicated)."""
    seen = set()
    resolved = []
    for name in available_tools:
        fns = _ALL_SAMPLING_TOOLS.get(name, [])
        for fn in fns:
            if fn.__name__ not in seen:
                seen.add(fn.__name__)
                resolved.append(fn)
    if not resolved:
        # fall back to the full set
        resolved = _FALLBACK_TOOLS
    return resolved


# ── Main tool ─────────────────────────────────────────────────────────────────

@app.tool()
async def agentic_file_workflow(
    workflow_prompt: str,
    available_tools: list[str],
    max_iterations: int = 5,
    ctx: Context = None,
) -> dict:
    """
    Execute agentic file workflows using FastMCP 2.14.1+ sampling with tools.

    Uses ctx.sample() with tools (SEP-1577) so the server's LLM autonomously
    orchestrates complex file management operations without client round-trips.

    MASSIVE EFFICIENCY GAINS:
    - LLM autonomously decides tool usage and sequencing
    - No client mediation for multi-step file operations
    - Structured validation and error recovery
    - Parallel processing capabilities

    FILE WORKFLOW EXAMPLES:
    - "Organize my project files" → autonomous file categorization and cleanup
    - "Backup important data" → intelligent backup orchestration
    - "Clean up old files" → automated file management and archiving

    Args:
        workflow_prompt: Description of the file workflow to execute
        available_tools: List of file tool names to make available to the LLM
        max_iterations: Maximum LLM-tool interaction loops (default: 5)

    Returns:
        Structured response with workflow execution results

    Example:
        # Organize project files workflow
        result = await agentic_file_workflow(
            workflow_prompt="Organize my project files by type",
            available_tools=["file_ops", "dir_ops", "search_ops"],
            max_iterations=10
        )
    """
    if not workflow_prompt:
        return _error_response(
            error="No workflow prompt provided",
            error_type="MISSING_WORKFLOW_PROMPT",
            recovery_options=["Provide a clear description of the file workflow to execute"],
        )

    if not available_tools:
        return _error_response(
            error="No tools specified",
            error_type="EMPTY_TOOLS_LIST",
            recovery_options=["Specify which file tools the LLM can use: file_ops, dir_ops, search_ops, read_ops"],
        )

    if ctx is None:
        return _error_response(
            error="No MCP context available — sampling requires a live client session",
            error_type="NO_CONTEXT",
            recovery_options=["Ensure this tool is called from an MCP-compatible client that supports sampling"],
        )

    tools = _resolve_tools(available_tools)

    system_prompt = (
        "You are a file management agent running on a Windows PC. "
        "Use the provided tools to complete the requested file workflow. "
        "Be systematic: check what exists before acting, read files to understand their content. "
        "Return a structured summary of what you found and did. "
        "Keep findings concise — prefer key facts over raw file dumps."
    )

    logger.info(
        "Starting agentic file workflow via ctx.sample()",
        extra={"workflow": workflow_prompt[:80], "tools": [t.__name__ for t in tools]},
    )

    try:
        sampling_result = await ctx.sample(
            messages=workflow_prompt,
            system_prompt=system_prompt,
            tools=tools,
            result_type=WorkflowResult,
            max_tokens=4096,
        )

        workflow: WorkflowResult = sampling_result.result

        return {
            "success": workflow.success,
            "operation": "agentic_file_workflow",
            "summary": workflow.summary,
            "result": {
                "workflow_prompt": workflow_prompt,
                "max_iterations_allowed": max_iterations,
                "steps_executed": workflow.steps_taken,
                "results": workflow.findings,
                "notes": workflow.notes,
                "execution_summary": {
                    "total_operations": len(workflow.steps_taken),
                    "results_count": len(workflow.findings),
                    "workflow_state": "completed",
                    "sampling_based": True,
                    "tools_available": [t.__name__ for t in tools],
                },
            },
            "execution_time_ms": None,  # sampling is async — not measured here
            "quality_metrics": {
                "steps_taken": len(workflow.steps_taken),
                "findings_count": len(workflow.findings),
                "autonomous_execution": True,
                "llm_orchestrated": True,
            },
            "recommendations": [
                "Review workflow findings to ensure they meet requirements",
            ],
            "next_steps": [
                "Use individual file_ops tools for targeted follow-up operations",
            ],
            "related_operations": ["file_ops", "dir_ops", "search_ops"],
        }

    except Exception as e:
        logger.error(f"Agentic file workflow sampling failed: {e}", exc_info=True)
        return _error_response(
            error=f"Sampling-based workflow failed: {str(e)}",
            error_type="SAMPLING_ERROR",
            recovery_options=[
                "Ensure the MCP client supports sampling (Claude Desktop does)",
                "Check that the client's LLM can handle tool-use requests",
                "Try a simpler workflow_prompt",
                "Check filesystem-mcp logs for details",
            ],
            diagnostic_info={
                "exception": str(e),
                "tools_resolved": [t.__name__ for t in tools],
                "workflow_type": "sampling_with_tools",
            },
        )
